{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4239bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#뇌파 데이터 불러오기\n",
    "df = pd.read_csv('./good_bad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c937f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "      <th>value3</th>\n",
       "      <th>value4</th>\n",
       "      <th>value5</th>\n",
       "      <th>value6</th>\n",
       "      <th>value7</th>\n",
       "      <th>value8</th>\n",
       "      <th>value9</th>\n",
       "      <th>value10</th>\n",
       "      <th>...</th>\n",
       "      <th>value92</th>\n",
       "      <th>value93</th>\n",
       "      <th>value94</th>\n",
       "      <th>value95</th>\n",
       "      <th>value96</th>\n",
       "      <th>value97</th>\n",
       "      <th>value98</th>\n",
       "      <th>value99</th>\n",
       "      <th>value100</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-470</td>\n",
       "      <td>-533</td>\n",
       "      <td>-458</td>\n",
       "      <td>-620</td>\n",
       "      <td>-883</td>\n",
       "      <td>-823</td>\n",
       "      <td>-545</td>\n",
       "      <td>-439</td>\n",
       "      <td>-596</td>\n",
       "      <td>-641</td>\n",
       "      <td>...</td>\n",
       "      <td>322</td>\n",
       "      <td>310</td>\n",
       "      <td>300</td>\n",
       "      <td>291</td>\n",
       "      <td>281</td>\n",
       "      <td>272</td>\n",
       "      <td>262</td>\n",
       "      <td>248</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>197</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>-9</td>\n",
       "      <td>-133</td>\n",
       "      <td>-183</td>\n",
       "      <td>-113</td>\n",
       "      <td>-97</td>\n",
       "      <td>...</td>\n",
       "      <td>-921</td>\n",
       "      <td>-1070</td>\n",
       "      <td>-909</td>\n",
       "      <td>-628</td>\n",
       "      <td>-605</td>\n",
       "      <td>-820</td>\n",
       "      <td>-849</td>\n",
       "      <td>-593</td>\n",
       "      <td>-469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-635</td>\n",
       "      <td>-697</td>\n",
       "      <td>-529</td>\n",
       "      <td>-394</td>\n",
       "      <td>-533</td>\n",
       "      <td>-750</td>\n",
       "      <td>-716</td>\n",
       "      <td>-613</td>\n",
       "      <td>-745</td>\n",
       "      <td>-963</td>\n",
       "      <td>...</td>\n",
       "      <td>513</td>\n",
       "      <td>1120</td>\n",
       "      <td>1460</td>\n",
       "      <td>1500</td>\n",
       "      <td>1700</td>\n",
       "      <td>2050</td>\n",
       "      <td>2050</td>\n",
       "      <td>2050</td>\n",
       "      <td>2050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2050</td>\n",
       "      <td>2050</td>\n",
       "      <td>2020</td>\n",
       "      <td>1680</td>\n",
       "      <td>1700</td>\n",
       "      <td>1860</td>\n",
       "      <td>1800</td>\n",
       "      <td>1530</td>\n",
       "      <td>1370</td>\n",
       "      <td>1380</td>\n",
       "      <td>...</td>\n",
       "      <td>824</td>\n",
       "      <td>674</td>\n",
       "      <td>533</td>\n",
       "      <td>666</td>\n",
       "      <td>736</td>\n",
       "      <td>460</td>\n",
       "      <td>218</td>\n",
       "      <td>281</td>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>332</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>274</td>\n",
       "      <td>230</td>\n",
       "      <td>-86</td>\n",
       "      <td>-178</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>-78</td>\n",
       "      <td>...</td>\n",
       "      <td>-195</td>\n",
       "      <td>-164</td>\n",
       "      <td>-132</td>\n",
       "      <td>-145</td>\n",
       "      <td>-166</td>\n",
       "      <td>-153</td>\n",
       "      <td>-123</td>\n",
       "      <td>-130</td>\n",
       "      <td>-149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>-4</td>\n",
       "      <td>-17</td>\n",
       "      <td>-2</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>84</td>\n",
       "      <td>139</td>\n",
       "      <td>183</td>\n",
       "      <td>200</td>\n",
       "      <td>208</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>235</td>\n",
       "      <td>278</td>\n",
       "      <td>274</td>\n",
       "      <td>211</td>\n",
       "      <td>170</td>\n",
       "      <td>176</td>\n",
       "      <td>185</td>\n",
       "      <td>193</td>\n",
       "      <td>186</td>\n",
       "      <td>178</td>\n",
       "      <td>...</td>\n",
       "      <td>-6</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-1</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>114</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>120</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>118</td>\n",
       "      <td>104</td>\n",
       "      <td>114</td>\n",
       "      <td>130</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>129</td>\n",
       "      <td>135</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>129</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-36</td>\n",
       "      <td>-55</td>\n",
       "      <td>-33</td>\n",
       "      <td>-8</td>\n",
       "      <td>-18</td>\n",
       "      <td>-29</td>\n",
       "      <td>-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     value1  value2  value3  value4  value5  value6  value7  value8  value9  \\\n",
       "0      -470    -533    -458    -620    -883    -823    -545    -439    -596   \n",
       "1       228     197      98       5      13      -9    -133    -183    -113   \n",
       "2      -635    -697    -529    -394    -533    -750    -716    -613    -745   \n",
       "3      2050    2050    2020    1680    1700    1860    1800    1530    1370   \n",
       "4       332      89      70     274     230     -86    -178       1     105   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "195      41      29      32      33      24      17      -4     -17      -2   \n",
       "196     235     278     274     211     170     176     185     193     186   \n",
       "197     114      87      51      42      61      65      58      66      68   \n",
       "198     129     135     139     139     129      99      52      35      49   \n",
       "199      22      53      59      53      55      66      76      71      48   \n",
       "\n",
       "     value10  ...  value92  value93  value94  value95  value96  value97  \\\n",
       "0       -641  ...      322      310      300      291      281      272   \n",
       "1        -97  ...     -921    -1070     -909     -628     -605     -820   \n",
       "2       -963  ...      513     1120     1460     1500     1700     2050   \n",
       "3       1380  ...      824      674      533      666      736      460   \n",
       "4        -78  ...     -195     -164     -132     -145     -166     -153   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "195       18  ...       88       58       84      139      183      200   \n",
       "196      178  ...       -6      -22      -22       -1       18       35   \n",
       "197       43  ...      125      120      132      132      118      104   \n",
       "198       73  ...        1       -1      -36      -55      -33       -8   \n",
       "199       67  ...      113      122      123      116      116      118   \n",
       "\n",
       "     value98  value99  value100  species  \n",
       "0        262      248       236        0  \n",
       "1       -849     -593      -469        0  \n",
       "2       2050     2050      2050        0  \n",
       "3        218      281       418        0  \n",
       "4       -123     -130      -149        0  \n",
       "..       ...      ...       ...      ...  \n",
       "195      208      210       211        1  \n",
       "196       26       37        84        1  \n",
       "197      114      130       124        1  \n",
       "198      -18      -29       -13        1  \n",
       "199      124      122       100        1  \n",
       "\n",
       "[200 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3d99aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value1  value2  value3  value4  value5  value6  value7  value8  value9  \\\n",
      "0    -470    -533    -458    -620    -883    -823    -545    -439    -596   \n",
      "1     228     197      98       5      13      -9    -133    -183    -113   \n",
      "2    -635    -697    -529    -394    -533    -750    -716    -613    -745   \n",
      "3    2050    2050    2020    1680    1700    1860    1800    1530    1370   \n",
      "4     332      89      70     274     230     -86    -178       1     105   \n",
      "\n",
      "   value10  ...  value91  value92  value93  value94  value95  value96  \\\n",
      "0     -641  ...      332      322      310      300      291      281   \n",
      "1      -97  ...     -786     -921    -1070     -909     -628     -605   \n",
      "2     -963  ...       48      513     1120     1460     1500     1700   \n",
      "3     1380  ...      706      824      674      533      666      736   \n",
      "4      -78  ...     -196     -195     -164     -132     -145     -166   \n",
      "\n",
      "   value97  value98  value99  value100  \n",
      "0      272      262      248       236  \n",
      "1     -820     -849     -593      -469  \n",
      "2     2050     2050     2050      2050  \n",
      "3      460      218      281       418  \n",
      "4     -153     -123     -130      -149  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#속성을 x, 클래스를 y로 지정하기\n",
    "X=df.iloc[:,0:100]\n",
    "y=df.iloc[:,100]\n",
    "\n",
    "#x와 y의 첫 보기\n",
    "print(X[0:5])\n",
    "print(y[0])\n",
    "print(y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5d85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습셋과 테스트셋으로 나누기\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11b36c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 30)                3030      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,515\n",
      "Trainable params: 3,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 구조를 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=100, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ff3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - val_loss: 0.0000e+00 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.4500\n",
      "Test accuracy: 0.44999998807907104\n"
     ]
    }
   ],
   "source": [
    "#모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#모델 실행\n",
    "history=model.fit(X_test, y_test, epochs=100, batch_size=30, validation_split=0.25)\n",
    "\n",
    "#테스트 결과 출력\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b041cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy  val_loss  val_accuracy\n",
       "0     0.0  0.600000       0.0           0.6\n",
       "1     0.0  0.600000       0.0           0.6\n",
       "2     0.0  0.600000       0.0           0.6\n",
       "3     0.0  0.466667       0.0           0.6\n",
       "4     0.0  0.400000       0.0           0.6\n",
       "..    ...       ...       ...           ...\n",
       "995   0.0  0.400000       0.0           0.6\n",
       "996   0.0  0.400000       0.0           0.6\n",
       "997   0.0  0.400000       0.0           0.6\n",
       "998   0.0  0.400000       0.0           0.6\n",
       "999   0.0  0.400000       0.0           0.6\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3887f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트셋, 학습셋의 오차 저장\n",
    "y_vloss=hist_df[\"val_loss\"]\n",
    "y_loss=hist_df[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6a722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#테스트셋 오차 : 빨간색, 학습셋의 오차 : 파란색\n",
    "x_len=np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label=\"Testset_loss\")\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label=\"Trainset_loss\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086c90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab6a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991306ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
